{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dbe9d25b",
      "metadata": {
        "id": "dbe9d25b"
      },
      "source": [
        "# HW05: Word Embeddings\n",
        "\n",
        "Remember that these homework work as a completion grade. **You can <span style=\"color:red\">not</span> skip one section this homework.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b3a0596",
      "metadata": {
        "id": "8b3a0596"
      },
      "source": [
        "**Essay Feedback**\n",
        "\n",
        "Please provide feedback to two classmates' essays on Eduflow."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea14794",
      "metadata": {
        "id": "5ea14794"
      },
      "source": [
        "**Training word2vec**\n",
        "\n",
        "In this section, we train a word2vec model using gensim. We train the model on text8 (which consists of the first 90M characters of a Wikipedia dump from 2006 and is considered one of the benchmarks for evaluating language models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "95a38d6e",
      "metadata": {
        "id": "95a38d6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'num_records': 1701,\n",
              " 'record_format': 'list of str (tokens)',\n",
              " 'file_size': 33182058,\n",
              " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n",
              " 'license': 'not found',\n",
              " 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n",
              " 'checksum': '68799af40b6bda07dfa47a32612e5364',\n",
              " 'file_name': 'text8.gz',\n",
              " 'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n",
              " 'parts': 1}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "api.info(\"text8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0a49444c",
      "metadata": {
        "id": "0a49444c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
          ]
        }
      ],
      "source": [
        "dataset = api.load(\"text8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "61fa38b5",
      "metadata": {
        "id": "61fa38b5"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "##TODO train a word2vec model on this dataset which appear at least 10 times in the corpus\n",
        "w2v = Word2Vec(dataset,\n",
        "               workers = 8,\n",
        "               vector_size = 300,\n",
        "               min_count = 10,\n",
        "               window = 5,\n",
        "               sample = 1e-3\n",
        "               )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af69360",
      "metadata": {
        "id": "4af69360"
      },
      "source": [
        "**Word Similarities**\n",
        "\n",
        "gensim models provide almost all the utility you might want to wish for to perform standard word similarity tasks. They are available in the .wv (wordvectors) attribute of the model, more details could be found [here](https://radimrehurek.com/gensim/models/keyedvectors.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5cf99280",
      "metadata": {
        "id": "5cf99280"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('prince', 0.6579781174659729),\n",
              " ('kings', 0.6461048722267151),\n",
              " ('throne', 0.616422176361084),\n",
              " ('emperor', 0.6078433394432068),\n",
              " ('queen', 0.6054559350013733),\n",
              " ('aragon', 0.6049193143844604),\n",
              " ('pharaoh', 0.5987396836280823),\n",
              " ('sultan', 0.5826488733291626),\n",
              " ('vii', 0.5816540718078613),\n",
              " ('sigismund', 0.5784335732460022)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model.wv\n",
        "\n",
        "##TODO find the closest words to king\n",
        "w2v.wv.most_similar('king')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c30c847",
      "metadata": {
        "id": "9c30c847"
      },
      "source": [
        "King is to man as woman is to X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "615b6116",
      "metadata": {
        "id": "615b6116"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('king', 0.8074710369110107),\n",
              " ('queen', 0.6103578209877014),\n",
              " ('throne', 0.5557685494422913),\n",
              " ('empress', 0.5511813759803772),\n",
              " ('prince', 0.5508004426956177),\n",
              " ('elizabeth', 0.5499032139778137),\n",
              " ('kings', 0.5362768769264221),\n",
              " ('daughter', 0.5321873426437378),\n",
              " ('reigning', 0.5302295088768005),\n",
              " ('emperor', 0.5291579365730286)]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##TODO find the closest word for the vector \"woman\" + \"king\" - \"man\"\n",
        "\n",
        "result_vector = w2v.wv['king'] - w2v.wv['man'] + w2v.wv['woman'] \n",
        "\n",
        "w2v.wv.most_similar(result_vector)\n",
        "\n",
        "## Answer: The closest word somehow is still \"king\" with \"queen\" being the second-closest."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2af37627",
      "metadata": {
        "id": "2af37627"
      },
      "source": [
        "**Evaluate Word Similarities** \n",
        "\n",
        "One common way to evaluate word2vec models are word analogy tasks. Let's check how good our model is on one of those. We consider the [WordSim353](http://alfonseca.org/eng/research/wordsim353.html) benchmark, the task is to determine how similar two words are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "71515b20",
      "metadata": {
        "id": "71515b20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  5460  100  5460    0     0  11147      0 --:--:-- --:--:-- --:--:-- 11234\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('tiger', 'cat'), ('tiger', 'tiger'), ('plane', 'car')] [7.35, 10.0, 5.77]\n"
          ]
        }
      ],
      "source": [
        "!curl -O http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
        "!tar xf ws353simrel.tar.gz\n",
        "\n",
        "path = \"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n",
        "\n",
        "def load_data(path):\n",
        "    X, y = [], []\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            line = line.strip().split(\"\\t\")\n",
        "            X.append((line[0], line[1])) # each entry in x contains two words, e.g. X[0] = (tiger, cat)\n",
        "            y.append(float(line[-1])) # each entry in y is the annotation how similar two words are, e.g. Y[0] = 7.35\n",
        "    return X, y\n",
        "\n",
        "X, y = load_data(path)\n",
        "print (X[:3], y[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "9c8ced33",
      "metadata": {
        "id": "9c8ced33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arafat: False --- Jackson: False\n",
            "asylum: True --- madhouse: False\n",
            "cup: True --- tableware: False\n",
            "Japanese: False --- American: False\n",
            "Harvard: False --- Yale: False\n",
            "Mexico: False --- Brazil: False\n",
            "Mars: False --- water: True\n",
            "Wednesday: False --- news: True\n",
            "stock: True --- CD: False\n"
          ]
        }
      ],
      "source": [
        "##TODO compute how similar the pairs in the WordSim353 are according to our model\n",
        "# if a word is not present in our model, we assign similarity 0 for the respective text pair\n",
        "\n",
        "def compare_w2v(X):\n",
        "    y = []\n",
        "    for (w1, w2) in X: # for each pair in X\n",
        "        if w1 in w2v.wv and w2 in w2v.wv: # ensure both words are in our model\n",
        "            y.append(w2v.wv.similarity(w1, w2))\n",
        "        else:\n",
        "            print('{}: {} --- {}: {}'.format(w1, w1 in w2v.wv, w2, w2 in w2v.wv))\n",
        "            y.append(0.0)\n",
        "    return y\n",
        "\n",
        "y_w2v = compare_w2v(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "ebd47f93",
      "metadata": {
        "id": "ebd47f93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6483163976197102"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "##TODO compute spearman's rank correlation between our prediction and the human annotations\n",
        "spearman_w2v = spearmanr(y, y_w2v)\n",
        "spearman_w2v.statistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "9ec86899",
      "metadata": {
        "id": "9ec86899"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\manth\\AppData\\Local\\Temp\\ipykernel_496\\3438373359.py:10: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  y.append(w1_.similarity(w2_))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0917488312498204"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "en = spacy.load('en_core_web_sm')\n",
        "\n",
        "##TODO compute word similarities in the WordSim353 dataset using spaCy word embeddings\n",
        "\n",
        "def compare_spacy(X):\n",
        "    y = []\n",
        "    for (w1, w2) in X: # for each pair in X\n",
        "        w1_, w2_ = en(w1), en(w2)\n",
        "        y.append(w1_.similarity(w2_))\n",
        "    return y\n",
        "\n",
        "y_spacy = compare_spacy(X)\n",
        "\n",
        "##TODO compute spearman's rank correlation between these similarities and the human annotations\n",
        "# Don't worry if results are not too convincing for this experiment\n",
        "\n",
        "spearman_spacy = spearmanr(y, y_spacy)\n",
        "spearman_spacy.statistic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d29de774",
      "metadata": {
        "id": "d29de774"
      },
      "source": [
        "**PyTorch Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3927e048",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-22T21:42:21.281177Z",
          "start_time": "2022-03-22T21:42:21.208787Z"
        },
        "id": "3927e048"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>lead</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69791</th>\n",
              "      <td>sport</td>\n",
              "      <td>Historic teams meet in World Series</td>\n",
              "      <td>CBC SPORTS ONLINE - It?s been 86 years since t...</td>\n",
              "      <td>Historic teams meet in World Series CBC SPORTS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83269</th>\n",
              "      <td>business</td>\n",
              "      <td>Former Merrill Lynch, Enron Employees Convicte...</td>\n",
              "      <td>Description: A jury in Houston finds four form...</td>\n",
              "      <td>Former Merrill Lynch, Enron Employees Convicte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49165</th>\n",
              "      <td>sci/tech</td>\n",
              "      <td>Translation Device Assists Minn. Police (AP)</td>\n",
              "      <td>AP - Burnsville police have begun using an ele...</td>\n",
              "      <td>Translation Device Assists Minn. Police (AP) A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96597</th>\n",
              "      <td>business</td>\n",
              "      <td>Big Dig Leaks Worse Than Thought</td>\n",
              "      <td>Leaks in the Big Dig highway tunnel system und...</td>\n",
              "      <td>Big Dig Leaks Worse Than Thought Leaks in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27894</th>\n",
              "      <td>sport</td>\n",
              "      <td>METS 7, BRAVES 0 Benson Gets 4-Hit Shutout</td>\n",
              "      <td>ris Benson, whose  quot;tired shoulder quot; b...</td>\n",
              "      <td>METS 7, BRAVES 0 Benson Gets 4-Hit Shutout ris...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          label                                              title  \\\n",
              "69791     sport                Historic teams meet in World Series   \n",
              "83269  business  Former Merrill Lynch, Enron Employees Convicte...   \n",
              "49165  sci/tech       Translation Device Assists Minn. Police (AP)   \n",
              "96597  business                   Big Dig Leaks Worse Than Thought   \n",
              "27894     sport         METS 7, BRAVES 0 Benson Gets 4-Hit Shutout   \n",
              "\n",
              "                                                    lead  \\\n",
              "69791  CBC SPORTS ONLINE - It?s been 86 years since t...   \n",
              "83269  Description: A jury in Houston finds four form...   \n",
              "49165  AP - Burnsville police have begun using an ele...   \n",
              "96597  Leaks in the Big Dig highway tunnel system und...   \n",
              "27894  ris Benson, whose  quot;tired shoulder quot; b...   \n",
              "\n",
              "                                                    text  \n",
              "69791  Historic teams meet in World Series CBC SPORTS...  \n",
              "83269  Former Merrill Lynch, Enron Employees Convicte...  \n",
              "49165  Translation Device Assists Minn. Police (AP) A...  \n",
              "96597  Big Dig Leaks Worse Than Thought Leaks in the ...  \n",
              "27894  METS 7, BRAVES 0 Benson Gets 4-Hit Shutout ris...  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Import the AG news dataset (same as hw01)\n",
        "#Download them from here \n",
        "# !wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "df.columns = [\"label\", \"title\", \"lead\"]\n",
        "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
        "def replace_label(x):\n",
        "\treturn label_map[x]\n",
        "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
        "df = df.sample(n=10000) # # only use 10K datapoints\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "a49d6b6e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-22T21:40:20.385383Z",
          "start_time": "2022-03-22T21:40:18.447956Z"
        },
        "id": "a49d6b6e"
      },
      "outputs": [],
      "source": [
        "vocab = 200\n",
        "##TODO tokenize the text, only keep 200 most frequent words \n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "df['tokens'] = df['text'].apply(lambda x: [tok for tok in word_tokenize(x) if tok.isalnum()]) # i am removing all punctuations\n",
        "flat_toks = [tok for tok_list in df['tokens'] for tok in tok_list]\n",
        "\n",
        "# now I can get the 200 most common by computing the freq_dist of the flattened list of tokens\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "fdist = FreqDist(flat_toks).most_common(vocab)\n",
        "most_common = [word for word, _ in fdist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "c4c0f840",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-22T21:40:23.322875Z",
          "start_time": "2022-03-22T21:40:23.311923Z"
        },
        "id": "c4c0f840"
      },
      "outputs": [],
      "source": [
        "length = 100\n",
        "#TODO create a one_hot representation for each word and truncate/pad the sequences such that they are all of the same length (here we use 100)\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "w_id = {word: index for index, word in enumerate(most_common)}\n",
        "\n",
        "one_hot_vec = [F.one_hot(torch.tensor(w_id[word]), num_classes=200) for word in most_common]\n",
        "one_hot_pad = pad_sequence(one_hot_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "c3d193dd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-22T21:40:28.364553Z",
          "start_time": "2022-03-22T21:40:28.354695Z"
        },
        "id": "c3d193dd"
      },
      "outputs": [],
      "source": [
        "##TODO create your torch embedding like we did in notebook 5! (hint: predicting labels: world, sport, business, and sci/tech)\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class EmbeddingNet(nn.Module):\n",
        "  def __init__(self, num_judges):\n",
        "    super(EmbeddingNet, self).__init__()\n",
        "    self.embedding = nn.Embedding(num_judges, 2)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(2, 2)\n",
        "    self.fc2 = nn.Linear(2, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "## I'm not very sure what the exact task is here or how to go about it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "2cac3bd2",
      "metadata": {
        "id": "2cac3bd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.system('jupyter nbconvert --to html homework_05.ipynb')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
